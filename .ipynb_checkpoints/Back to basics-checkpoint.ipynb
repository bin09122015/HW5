{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import statistics\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "# Need to upgrade scikit-learn: 0.16.1-np110py34_0 --> 0.17-np110py34_1\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.4239</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>-0.0822</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>-0.3922</td>\n",
       "      <td>1.0266</td>\n",
       "      <td>-0.0727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4980</td>\n",
       "      <td>0.2699</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.3439</td>\n",
       "      <td>-0.7132</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>0.4908</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0333</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>1.6477</td>\n",
       "      <td>-0.0055</td>\n",
       "      <td>1.3492</td>\n",
       "      <td>1.7797</td>\n",
       "      <td>0.2373</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.5364</td>\n",
       "      <td>0.8107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4338</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.1612</td>\n",
       "      <td>0.5061</td>\n",
       "      <td>0.5414</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.7769</td>\n",
       "      <td>0.4816</td>\n",
       "      <td>0.0153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8575</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>1.2054</td>\n",
       "      <td>0.3284</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>-0.7346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>-0.5545</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>1.0189</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.4692</td>\n",
       "      <td>0.5448</td>\n",
       "      <td>-0.0717</td>\n",
       "      <td>0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.1823</td>\n",
       "      <td>0.2093</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>-0.0356</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>-0.0576</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.2704</td>\n",
       "      <td>-0.6897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3531</td>\n",
       "      <td>0.6247</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.8186</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.9516</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>-0.0349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.1017</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>-0.2274</td>\n",
       "      <td>-0.3208</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>-0.7160</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>1.2310</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>-0.1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.2734</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.2898</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.8335</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>1.0904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0       1       2       3       4       5       6       7       8    \\\n",
       "0 -0.4239  0.2575 -0.0822  0.0319  0.0466  0.2167  0.6265 -0.3922  1.0266   \n",
       "1  1.0333 -0.4939  1.6477 -0.0055  1.3492  1.7797  0.2373  0.1058  0.5364   \n",
       "2  0.8575  0.3404  0.4440  1.2054  0.3284  0.2136  0.2860  0.7980  0.3267   \n",
       "3 -0.1823  0.2093  0.2319 -0.0356  0.5622  0.8247 -0.0576  0.1797  0.2704   \n",
       "4 -0.1017  0.8511 -0.2274 -0.3208  0.0737 -0.7160  0.3360  1.2310  0.0852   \n",
       "\n",
       "      9     ...       290     291     292     293     294     295     296  \\\n",
       "0 -0.0727   ...    0.4980  0.2699  0.4495  0.7003  0.3439 -0.7132  0.4380   \n",
       "1  0.8107   ...    0.4338  0.1347  0.1612  0.5061  0.5414  0.9960  0.0388   \n",
       "2 -0.7346   ...    0.3418 -0.5545  0.9698  1.0189  0.2874  0.0385  0.4692   \n",
       "3 -0.6897   ...   -0.3531  0.6247  0.0404  0.2691  0.8186  0.4396  0.9516   \n",
       "4 -0.1950   ...    0.5686  0.8175  0.3609  0.2734  0.9901  0.2898  0.0942   \n",
       "\n",
       "      297     298     299  \n",
       "0  0.8871  0.4908  0.6784  \n",
       "1  0.7769  0.4816  0.0153  \n",
       "2  0.5448 -0.0717  0.0085  \n",
       "3  0.2424  0.1820 -0.0349  \n",
       "4  0.8335  0.0841  1.0904  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deal with input data\n",
    "trainX = pd.read_csv('trainingData.txt','\\t', header = None)\n",
    "trainX = trainX.fillna(trainX.median())\n",
    "trainX.drop(trainX.columns[len(trainX.columns)-1], axis = 1, inplace = True)\n",
    "trainY = pd.read_csv(\"trainingTruth.txt\", header = None, names = ['Y'])\n",
    "\n",
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3388</td>\n",
       "      <td>-0.6134</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>-0.3948</td>\n",
       "      <td>-0.1955</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>-0.0207</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>1.0321</td>\n",
       "      <td>0.4876</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0299</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.4740</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.3605</td>\n",
       "      <td>-0.1622</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>0.6892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0323</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>-0.3896</td>\n",
       "      <td>-0.3152</td>\n",
       "      <td>0.4111</td>\n",
       "      <td>0.8192</td>\n",
       "      <td>-0.0835</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5294</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.6086</td>\n",
       "      <td>0.7871</td>\n",
       "      <td>0.2934</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>-0.0150</td>\n",
       "      <td>-0.1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4210</td>\n",
       "      <td>-0.6115</td>\n",
       "      <td>-0.4676</td>\n",
       "      <td>-0.2676</td>\n",
       "      <td>0.7558</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>-0.7681</td>\n",
       "      <td>0.1749</td>\n",
       "      <td>0.3633</td>\n",
       "      <td>-0.2896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>-0.0134</td>\n",
       "      <td>0.8386</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.5321</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>1.5449</td>\n",
       "      <td>0.8187</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>0.4920</td>\n",
       "      <td>0.6083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6971</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>-0.7569</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>-0.5789</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.3237</td>\n",
       "      <td>-0.2974</td>\n",
       "      <td>0.1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.6924</td>\n",
       "      <td>0.4005</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>-0.3483</td>\n",
       "      <td>-0.2414</td>\n",
       "      <td>0.3969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5147</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.5237</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>-0.0569</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.3326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0       1       2       3       4       5       6       7       8    \\\n",
       "0  0.3388 -0.6134  0.6599 -0.3948 -0.1955  0.6260 -0.0207  0.4010  1.0321   \n",
       "1 -0.0323  0.7150 -0.3896 -0.3152  0.4111  0.8192 -0.0835  0.4744  0.6452   \n",
       "2  0.4210 -0.6115 -0.4676 -0.2676  0.7558  0.9202 -0.7681  0.1749  0.3633   \n",
       "3  0.0244  0.5321  0.6697  0.9791  1.5449  0.8187  0.2670  0.8483  0.4920   \n",
       "4 -0.0067  0.1359  0.2470  0.8615  0.6924  0.4005  0.3690 -0.3483 -0.2414   \n",
       "\n",
       "      9     ...       290     291     292     293     294     295     296  \\\n",
       "0  0.4876   ...    1.0299  0.3046  0.4740  0.0193  0.3605 -0.1622  0.8764   \n",
       "1  0.5598   ...    0.5294  0.8250  0.2874  0.6086  0.7871  0.2934  0.1313   \n",
       "2 -0.2896   ...    0.2658 -0.0134  0.8386  0.0123  0.0963  0.3816  0.1861   \n",
       "3  0.6083   ...    0.6971  0.1315  0.0271 -0.7569  0.9737 -0.5789  0.1209   \n",
       "4  0.3969   ...   -0.5147 -0.0006  0.5237  0.6780  0.2294 -0.0569  0.1377   \n",
       "\n",
       "      297     298     299  \n",
       "0  0.0448  0.6939  0.6892  \n",
       "1  0.4317 -0.0150 -0.1622  \n",
       "2  0.6514  0.1735  0.6902  \n",
       "3  0.3237 -0.2974  0.1895  \n",
       "4  0.9044  0.0683  0.3326  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX = pd.read_csv('testData.txt','\\t', header = None)\n",
    "testX.drop(testX.columns[len(testX.columns)-1], axis = 1, inplace = True)\n",
    "testX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators=20)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "clf4 = DecisionTreeClassifier(max_depth=4)\n",
    "clf5 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf6 = SVC(kernel='rbf', probability=True)\n",
    "clf7 = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),\n",
    "                                     ('dt', clf4), ('kn', clf5), ('svc', clf6),\n",
    "                                     ('ab', clf7)], voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "from sklearn.cross_validation import ShuffleSplit,KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "X = trainX.values\n",
    "Y = np.ravel(trainY.values)\n",
    "\n",
    "def CV_auc(X, Y, clf):\n",
    "    \n",
    "    ss = ShuffleSplit(n=len(Y), n_iter=10, test_size=0.2, random_state=1)\n",
    "    kf = KFold(len(Y), n_folds=10)\n",
    "\n",
    "    scores = []\n",
    "    roc_auc_scores = []\n",
    "    \n",
    "    for train, test in ss:\n",
    "        clf = clf.fit(X[train], Y[train])\n",
    "        results = clf.predict(X[test])\n",
    "        score = accuracy_score(Y[test], results)\n",
    "        scores.append(score)\n",
    "\n",
    "        probas = clf.predict_proba(X[test])\n",
    "\n",
    "\n",
    "        roc_auc = np.zeros((3,1))\n",
    "        for i in range(1,4):\n",
    "            false_positive_rate, recall, thresholds = roc_curve(Y[test], probas[:,i-1], pos_label=i)\n",
    "            roc_auc[i-1] = auc(false_positive_rate, recall)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    print(np.mean(scores),np.std(scores))\n",
    "    print(np.mean(roc_auc_scores, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.849587824984 0.00718287914259\n",
      "[[ 0.96449522]\n",
      " [ 0.92579075]\n",
      " [ 0.96115477]]\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "            oob_score=False, random_state=1, verbose=0, warm_start=False)\n",
      "0.657641090679 0.00637561971555\n",
      "[[ 0.87847298]\n",
      " [ 0.75403245]\n",
      " [ 0.84788402]]\n",
      "GaussianNB()\n",
      "0.860145846544 0.00491889253511\n",
      "[[ 0.96831445]\n",
      " [ 0.94265475]\n",
      " [ 0.96741723]]\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.49927076728 0.00896780216348\n",
      "[[ 0.70131584]\n",
      " [ 0.61615145]\n",
      " [ 0.70104311]]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n",
      "0.718833227647 0.00768012981698\n",
      "[[ 0.95770276]\n",
      " [ 0.84541011]\n",
      " [ 0.93261361]]\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.865440710209 0.00485046478307\n",
      "[[ 0.97168225]\n",
      " [ 0.94665727]\n",
      " [ 0.96789043]]\n"
     ]
    }
   ],
   "source": [
    "for clf in [clf1, clf2, clf3, clf4, clf5, clf6]:\n",
    "    print(clf)\n",
    "    CV_auc(X, Y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf3 = clf3.fit(X, Y)\n",
    "proba = clf3.predict_proba(testX.values)\n",
    "prediction = clf.predict(testX.values)\n",
    "\n",
    "results = pd.DataFrame(proba)\n",
    "results['prediction'] = prediction\n",
    "\n",
    "results.to_csv('testY.txt', sep='\\t', header = False, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
