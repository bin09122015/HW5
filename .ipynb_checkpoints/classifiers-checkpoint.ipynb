{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import statistics\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainX = pd.read_csv('trainingData.txt','\\t', header = None)\n",
    "trainX.drop(trainX.columns[len(trainX.columns)-1], axis = 1, inplace = True)\n",
    "trainY = pd.read_csv(\"trainingTruth.txt\", header = None, names = ['Y'])\n",
    "df = trainX.join(trainY)\n",
    "# relax the limit a bit, since the cross_val_score is dropping with 1\n",
    "index = df.isnull().sum(axis=1) <= 2\n",
    "df = df[index]\n",
    "df.fillna(df.median(), inplace = True)  \n",
    "# Is it better to delete the rows with NA in the training? Fill in median could mislead the classifier.\n",
    "# How about dropping all the rows with NA using the following line?\n",
    "# df.dropna(axis=0, inplace=True) # drop the row with NA in training.\n",
    "X = df.iloc[:,0:-1].values\n",
    "Y = df['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9861.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,  5527.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWoYDJKkhsEgSWoYDJKkhsEgSWr8P3UegH2K/yocAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117a0b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_binary = np.ones((len(Y),3)) * (-1)\n",
    "for i in range(3):\n",
    "    index = Y == (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "# Need to upgrade scikit-learn: 0.16.1-np110py34_0 --> 0.17-np110py34_1\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators=20)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "clf4 = DecisionTreeClassifier(max_depth=4)\n",
    "clf5 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf6 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),\n",
    "                                     ('dt', clf4), ('kn', clf5), ('svc', clf6)], \n",
    "                         voting='hard')\n",
    "eclf2 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),\n",
    "                                     ('dt', clf4), ('kn', clf5), ('svc', clf6)], \n",
    "                         voting='soft')\n",
    "#eclf3 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard voting 0.853845957819 0.00799991819654\n",
      "soft voting 0.868338889238 0.00540095906608\n"
     ]
    }
   ],
   "source": [
    "score1 = cross_val_score(eclf1, X, Y, cv=10)\n",
    "score2 = cross_val_score(eclf2, X, Y, cv=10)\n",
    "#score3 = cross_val_score(eclf3, X, Y, cv=10)\n",
    "\n",
    "print('hard voting', np.mean(score1), np.std(score1))\n",
    "print('soft voting', np.mean(score2), np.std(score2))\n",
    "#print('soft voting by weight', np.mean(score3), np.std(score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard voting 0.887770306248 0.006194520852\n",
      "soft voting 0.889523889502 0.00437884476615\n"
     ]
    }
   ],
   "source": [
    "# Reduce X dimension, Test if the results stay the same\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_PCA = PCA(n_components=30).fit_transform(X_scaled)\n",
    "\n",
    "score1 = cross_val_score(eclf1, X_PCA, Y, cv=10)\n",
    "score2 = cross_val_score(eclf2, X_PCA, Y, cv=10)\n",
    "\n",
    "print('hard voting', np.mean(score1), np.std(score1))\n",
    "print('soft voting', np.mean(score2), np.std(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84805195  0.85324675  0.84535413  0.84015595  0.86289799  0.84795322\n",
      "  0.84080572  0.85045514  0.84980494  0.84710475]\n",
      "[ 0.86753247  0.87792208  0.86159844  0.8602989   0.87264457  0.86159844\n",
      "  0.87004548  0.86345904  0.87516255  0.86532206]\n",
      "[ 0.87012987  0.87727273  0.86419753  0.85834958  0.87979207  0.86289799\n",
      "  0.86224821  0.86736021  0.86345904  0.86662329]\n",
      "[ 0.81688312  0.82012987  0.80116959  0.79597141  0.82131254  0.79922027\n",
      "  0.79402209  0.78153446  0.79323797  0.81522446]\n",
      "[ 0.87727273  0.88051948  0.8648473   0.87069526  0.88304094  0.86419753\n",
      "  0.87719298  0.86996099  0.87711313  0.870527  ]\n",
      "[ 0.90584416  0.91038961  0.90253411  0.89408707  0.90643275  0.90903184\n",
      "  0.89993502  0.90052016  0.91092328  0.90761223]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_PCA = PCA(n_components=30).fit_transform(X_scaled)\n",
    "\n",
    "print(cross_val_score(clf1, X_PCA, Y, cv=10))\n",
    "print(cross_val_score(clf2, X_PCA, Y, cv=10))\n",
    "print(cross_val_score(clf3, X_PCA, Y, cv=10))\n",
    "print(cross_val_score(clf4, X_PCA, Y, cv=10))\n",
    "print(cross_val_score(clf5, X_PCA, Y, cv=10))\n",
    "print(cross_val_score(clf6, X_PCA, Y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC is most accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf7 = AdaBoostClassifier(random_state=1, base_estimator=clf6, algorithm='SAMME')\n",
    "print(cross_val_score(clf7, X_PCA, Y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.81828108  0.18171892]\n",
      " [ 0.19317488  0.80682512]\n",
      " [ 0.83543036  0.16456964]\n",
      " [ 0.83543345  0.16456655]\n",
      " [ 0.8355132   0.1644868 ]\n",
      " [ 0.83535393  0.16464607]\n",
      " [ 0.14250572  0.85749428]\n",
      " [ 0.83557461  0.16442539]\n",
      " [ 0.8354108   0.1645892 ]\n",
      " [ 0.83554599  0.16445401]\n",
      " [ 0.82787794  0.17212206]\n",
      " [ 0.76710361  0.23289639]\n",
      " [ 0.83508241  0.16491759]\n",
      " [ 0.79908293  0.20091707]\n",
      " [ 0.43226237  0.56773763]\n",
      " [ 0.86957731  0.13042269]\n",
      " [ 0.83533444  0.16466556]\n",
      " [ 0.83537505  0.16462495]\n",
      " [ 0.83561691  0.16438309]\n",
      " [ 0.39407773  0.60592227]\n",
      " [ 0.30062942  0.69937058]\n",
      " [ 0.83517734  0.16482266]\n",
      " [ 0.50604203  0.49395797]\n",
      " [ 0.83543877  0.16456123]\n",
      " [ 0.12943166  0.87056834]\n",
      " [ 0.83521483  0.16478517]\n",
      " [ 0.79804931  0.20195069]\n",
      " [ 0.18330551  0.81669449]\n",
      " [ 0.32258984  0.67741016]\n",
      " [ 0.20212993  0.79787007]\n",
      " [ 0.15263333  0.84736667]\n",
      " [ 0.83533839  0.16466161]\n",
      " [ 0.83528317  0.16471683]\n",
      " [ 0.83533859  0.16466141]\n",
      " [ 0.83503491  0.16496509]\n",
      " [ 0.83540267  0.16459733]\n",
      " [ 0.38723368  0.61276632]\n",
      " [ 0.8354932   0.1645068 ]\n",
      " [ 0.28759714  0.71240286]\n",
      " [ 0.83505539  0.16494461]\n",
      " [ 0.83524876  0.16475124]\n",
      " [ 0.83534824  0.16465176]\n",
      " [ 0.23918751  0.76081249]\n",
      " [ 0.26608661  0.73391339]\n",
      " [ 0.83528886  0.16471114]\n",
      " [ 0.83521826  0.16478174]\n",
      " [ 0.83536095  0.16463905]\n",
      " [ 0.35233909  0.64766091]\n",
      " [ 0.83537659  0.16462341]\n",
      " [ 0.83534069  0.16465931]\n",
      " [ 0.36262731  0.63737269]\n",
      " [ 0.24099149  0.75900851]\n",
      " [ 0.82389055  0.17610945]\n",
      " [ 0.84525068  0.15474932]\n",
      " [ 0.8354359   0.1645641 ]\n",
      " [ 0.82227838  0.17772162]\n",
      " [ 0.8352634   0.1647366 ]\n",
      " [ 0.83503155  0.16496845]\n",
      " [ 0.83556727  0.16443273]\n",
      " [ 0.22992945  0.77007055]\n",
      " [ 0.83855925  0.16144075]\n",
      " [ 0.84348706  0.15651294]\n",
      " [ 0.23625586  0.76374414]\n",
      " [ 0.83540043  0.16459957]\n",
      " [ 0.15907755  0.84092245]\n",
      " [ 0.8354188   0.1645812 ]\n",
      " [ 0.83563458  0.16436542]\n",
      " [ 0.83531188  0.16468812]\n",
      " [ 0.368188    0.631812  ]\n",
      " [ 0.83865604  0.16134396]\n",
      " [ 0.8353966   0.1646034 ]\n",
      " [ 0.83541455  0.16458545]\n",
      " [ 0.83523729  0.16476271]\n",
      " [ 0.27542709  0.72457291]\n",
      " [ 0.39116632  0.60883368]\n",
      " [ 0.83549997  0.16450003]\n",
      " [ 0.83540656  0.16459344]\n",
      " [ 0.88282056  0.11717944]\n",
      " [ 0.83548668  0.16451332]\n",
      " [ 0.83539248  0.16460752]\n",
      " [ 0.83527721  0.16472279]\n",
      " [ 0.83965831  0.16034169]\n",
      " [ 0.54168389  0.45831611]\n",
      " [ 0.17573712  0.82426288]\n",
      " [ 0.26722394  0.73277606]\n",
      " [ 0.3227934   0.6772066 ]\n",
      " [ 0.83536748  0.16463252]\n",
      " [ 0.86119235  0.13880765]\n",
      " [ 0.83524794  0.16475206]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.83518422  0.16481578]\n",
      " [ 0.22875424  0.77124576]\n",
      " [ 0.82814822  0.17185178]\n",
      " [ 0.14844611  0.85155389]\n",
      " [ 0.83389068  0.16610932]\n",
      " [ 0.83535385  0.16464615]\n",
      " [ 0.35526048  0.64473952]\n",
      " [ 0.23032348  0.76967652]\n",
      " [ 0.83560742  0.16439258]\n",
      " [ 0.8353816   0.1646184 ]]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "[2 3 2 2 1 1 3 1 2 1 2 2 1 2 3 1 2 1 2 3 3 2 3 2 3 1 2 3 3 3 3 2 2 2 1 2 3\n",
      " 2 3 2 2 2 3 3 2 1 2 3 2 1 3 3 2 2 2 2 2 1 1 3 2 1 3 2 3 2 2 2 3 2 1 2 2 3\n",
      " 3 1 1 2 2 1 1 1 3 3 3 3 1 1 1 3 2 3 2 3 2 2 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "sampleX = X[0:100,:]\n",
    "sampleY_binary = Y_binary[0:100,:]\n",
    "clf6 = clf6.fit(sampleX,sampleY_binary[:,2])\n",
    "print(clf6.predict_proba(sampleX))\n",
    "print(clf6.predict(sampleX))\n",
    "print(Y[0:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
