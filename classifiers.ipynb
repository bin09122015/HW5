{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import statistics\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainX = pd.read_csv('trainingData.txt','\\t', header = None)\n",
    "trainX.drop(trainX.columns[len(trainX.columns)-1], axis = 1, inplace = True)\n",
    "trainY = pd.read_csv(\"trainingTruth.txt\", header = None, names = ['Y'])\n",
    "df = trainX.join(trainY)\n",
    "# relax the limit a bit, since the cross_val_score is dropping with 1\n",
    "index = df.isnull().sum(axis=1) <= 2\n",
    "df = df[index]\n",
    "df.fillna(df.median(), inplace = True)  \n",
    "# Is it better to delete the rows with NA in the training? Fill in median could mislead the classifier.\n",
    "# How about dropping all the rows with NA using the following line?\n",
    "# df.dropna(axis=0, inplace=True) # drop the row with NA in training.\n",
    "X = df.iloc[:,0:-1].values\n",
    "Y = df['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# Need to upgrade scikit-learn: 0.16.1-np110py34_0 --> 0.17-np110py34_1\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators=20)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "clf4 = DecisionTreeClassifier(max_depth=4)\n",
    "clf5 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf6 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),\n",
    "                                     ('dt', clf4), ('kn', clf5), ('svc', clf6)], \n",
    "                         voting='hard')\n",
    "eclf2 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),\n",
    "                                     ('dt', clf4), ('kn', clf5), ('svc', clf6)], \n",
    "                         voting='soft')\n",
    "#eclf3 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard voting 0.853845957819 0.00799991819654\n",
      "soft voting 0.868338889238 0.00540095906608\n"
     ]
    }
   ],
   "source": [
    "score1 = cross_val_score(eclf1, X, Y, cv=10)\n",
    "score2 = cross_val_score(eclf2, X, Y, cv=10)\n",
    "#score3 = cross_val_score(eclf3, X, Y, cv=10)\n",
    "\n",
    "print('hard voting', np.mean(score1), np.std(score1))\n",
    "print('soft voting', np.mean(score2), np.std(score2))\n",
    "#print('soft voting by weight', np.mean(score3), np.std(score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard voting 0.887770306248 0.006194520852\n",
      "soft voting 0.889523889502 0.00437884476615\n"
     ]
    }
   ],
   "source": [
    "# Reduce X dimension, Test if the results stay the same\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_PCA = PCA(n_components=30).fit_transform(X_scaled)\n",
    "\n",
    "score1 = cross_val_score(eclf1, X_PCA, Y, cv=10)\n",
    "score2 = cross_val_score(eclf2, X_PCA, Y, cv=10)\n",
    "\n",
    "print('hard voting', np.mean(score1), np.std(score1))\n",
    "print('soft voting', np.mean(score2), np.std(score2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
