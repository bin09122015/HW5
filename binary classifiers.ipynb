{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import statistics\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "# Need to upgrade scikit-learn: 0.16.1-np110py34_0 --> 0.17-np110py34_1\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15388\n"
     ]
    }
   ],
   "source": [
    "# Deal with input data\n",
    "trainX = pd.read_csv('trainingData.txt','\\t', header = None)\n",
    "trainX.drop(trainX.columns[len(trainX.columns)-1], axis = 1, inplace = True)\n",
    "trainY = pd.read_csv(\"trainingTruth.txt\", header = None, names = ['Y'])\n",
    "df = pd.concat([trainX, trainY], axis=1)\n",
    "index = df.isnull().sum(axis=1) <= 2\n",
    "df = df[index]\n",
    "df.fillna(df.median(), inplace = True)\n",
    "print(len(df))\n",
    "\n",
    "X = df.iloc[:,0:-1].values\n",
    "Y = df['Y'].values\n",
    "\n",
    "Y_binary = np.ones((len(Y),3)) * (-1)\n",
    "for i in range(3):\n",
    "    index = Y == (i+1)\n",
    "    Y_binary[index,i] = 1\n",
    "    \n",
    "testX = pd.read_csv('testData.txt','\\t', header = None)\n",
    "testX.drop(testX.columns[len(testX.columns)-1], axis = 1, inplace = True)\n",
    "testX.fillna(testX.median(), inplace = True) # Handle NA in test data, although not necessary for this assignment.\n",
    "\n",
    "# Build classifiers\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators=20)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "clf4 = DecisionTreeClassifier(max_depth=4)\n",
    "clf5 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf6 = SVC(kernel='rbf', probability=True)\n",
    "clf7 = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),\n",
    "                                     ('dt', clf4), ('kn', clf5), ('svc', clf6)], \n",
    "                        voting='soft', weights = [8, 2, 3, 1, 2, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainAndPredict(clf, trainX, trainY, testX, dimensionReduction = True, n_components = 30):\n",
    "    \n",
    "    n_train = len(trainX)\n",
    "    n_test = len(testX)\n",
    "    X = np.concatenate((trainX, testX), axis=0)\n",
    "    \n",
    "    if dimensionReduction:        \n",
    "        X = preprocessing.scale(X)\n",
    "        X = PCA(n_components=n_components).fit_transform(X)\n",
    "    \n",
    "    trainX = X[0:n_train]\n",
    "    testX = X[n_train: n_train+n_test+1]\n",
    "\n",
    "    proba = np.zeros((len(testX),3))\n",
    "    \n",
    "    if len(trainY.shape) > 1:\n",
    "        for i in range(trainY.shape[1]):\n",
    "            clf = clf.fit(trainX,trainY[:,i])\n",
    "            proba[:,i] = clf.predict_proba(testX)[:,1]\n",
    "    else:\n",
    "        clf = clf.fit(trainX, trainY)\n",
    "        proba = clf.predict_proba(testX)\n",
    "\n",
    "    # Write to file\n",
    "    results = pd.DataFrame(proba)\n",
    "    results['prediction'] = np.argmax(proba, axis=1) + 1\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get results, write to file, and print out training accuracy\n",
    "results = trainAndPredict(eclf, X, Y_binary, X)\n",
    "#results.to_csv('testY.txt', sep='\\t', header = False, index = False)\n",
    "print('training accuracy',accuracy_score(Y, results['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907732293697 0.00422102190225\n"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "from sklearn.cross_validation import ShuffleSplit,KFold\n",
    "\n",
    "ss = ShuffleSplit(n=len(Y), n_iter=10, test_size=0.1, random_state=1)\n",
    "#kf = KFold(len(Y), n_folds=10)\n",
    "scores = []\n",
    "for train, test in ss:\n",
    "    results = trainAndPredict(clf6, X[train], Y_binary[train], X[test])\n",
    "    scores.append(accuracy_score(Y[test], results['prediction']))\n",
    "                  \n",
    "print(np.mean(scores),np.std(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
